Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
18/07/13 19:14:44 INFO SparkContext: Running Spark version 2.2.0
18/07/13 19:14:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/07/13 19:14:45 WARN Utils: Your hostname, vallanta resolves to a loopback address: 127.0.1.1; using 130.192.16.68 instead (on interface eth0)
18/07/13 19:14:45 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
18/07/13 19:14:45 INFO SparkContext: Submitted application: Spark Exam 2018_07_16 - Exercise #2 - v2
18/07/13 19:14:45 INFO SecurityManager: Changing view acls to: paolo
18/07/13 19:14:45 INFO SecurityManager: Changing modify acls to: paolo
18/07/13 19:14:45 INFO SecurityManager: Changing view acls groups to: 
18/07/13 19:14:45 INFO SecurityManager: Changing modify acls groups to: 
18/07/13 19:14:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(paolo); groups with view permissions: Set(); users  with modify permissions: Set(paolo); groups with modify permissions: Set()
18/07/13 19:14:45 INFO Utils: Successfully started service 'sparkDriver' on port 19272.
18/07/13 19:14:45 INFO SparkEnv: Registering MapOutputTracker
18/07/13 19:14:45 INFO SparkEnv: Registering BlockManagerMaster
18/07/13 19:14:45 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/07/13 19:14:45 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/07/13 19:14:45 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-07d4b30a-0637-4838-9777-0e7b1101d1cf
18/07/13 19:14:45 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/07/13 19:14:45 INFO SparkEnv: Registering OutputCommitCoordinator
18/07/13 19:14:45 INFO Utils: Successfully started service 'SparkUI' on port 4040.
18/07/13 19:14:45 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://130.192.16.68:4040
18/07/13 19:14:45 INFO SparkContext: Added JAR file:/home/paolo/Dropbox/owncloud/Corsi/BigData1718/Exams_AA1718/Exam20180716/BozzaSoluzionev2/Exercise2/target/Exam2018_07_16_Exercise2_v2-1.0.0.jar at spark://130.192.16.68:19272/jars/Exam2018_07_16_Exercise2_v2-1.0.0.jar with timestamp 1531502085906
18/07/13 19:14:45 INFO Executor: Starting executor ID driver on host localhost
18/07/13 19:14:46 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 20152.
18/07/13 19:14:46 INFO NettyBlockTransferService: Server created on 130.192.16.68:20152
18/07/13 19:14:46 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/07/13 19:14:46 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 130.192.16.68, 20152, None)
18/07/13 19:14:46 INFO BlockManagerMasterEndpoint: Registering block manager 130.192.16.68:20152 with 366.3 MB RAM, BlockManagerId(driver, 130.192.16.68, 20152, None)
18/07/13 19:14:46 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 130.192.16.68, 20152, None)
18/07/13 19:14:46 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 130.192.16.68, 20152, None)
18/07/13 19:14:46 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 214.5 KB, free 366.1 MB)
18/07/13 19:14:46 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 366.1 MB)
18/07/13 19:14:46 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 130.192.16.68:20152 (size: 20.4 KB, free: 366.3 MB)
18/07/13 19:14:46 INFO SparkContext: Created broadcast 0 from textFile at SparkDriver.java:35
18/07/13 19:14:46 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 214.5 KB, free 365.9 MB)
18/07/13 19:14:46 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 20.4 KB, free 365.8 MB)
18/07/13 19:14:46 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 130.192.16.68:20152 (size: 20.4 KB, free: 366.3 MB)
18/07/13 19:14:46 INFO SparkContext: Created broadcast 1 from textFile at SparkDriver.java:50
18/07/13 19:14:46 INFO FileInputFormat: Total input paths to process : 1
18/07/13 19:14:46 INFO FileInputFormat: Total input paths to process : 1
18/07/13 19:14:46 INFO SparkContext: Starting job: saveAsTextFile at SparkDriver.java:101
18/07/13 19:14:46 INFO DAGScheduler: Registering RDD 2 (mapToPair at SparkDriver.java:40)
18/07/13 19:14:46 INFO DAGScheduler: Registering RDD 6 (mapToPair at SparkDriver.java:69)
18/07/13 19:14:46 INFO DAGScheduler: Registering RDD 10 (mapToPair at SparkDriver.java:88)
18/07/13 19:14:46 INFO DAGScheduler: Got job 0 (saveAsTextFile at SparkDriver.java:101) with 1 output partitions
18/07/13 19:14:46 INFO DAGScheduler: Final stage: ResultStage 3 (saveAsTextFile at SparkDriver.java:101)
18/07/13 19:14:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
18/07/13 19:14:46 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
18/07/13 19:14:46 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at mapToPair at SparkDriver.java:40), which has no missing parents
18/07/13 19:14:46 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 4.7 KB, free 365.8 MB)
18/07/13 19:14:46 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.7 KB, free 365.8 MB)
18/07/13 19:14:46 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 130.192.16.68:20152 (size: 2.7 KB, free: 366.3 MB)
18/07/13 19:14:46 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
18/07/13 19:14:46 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at mapToPair at SparkDriver.java:40) (first 15 tasks are for partitions Vector(0))
18/07/13 19:14:46 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
18/07/13 19:14:46 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[6] at mapToPair at SparkDriver.java:69), which has no missing parents
18/07/13 19:14:46 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 5.1 KB, free 365.8 MB)
18/07/13 19:14:46 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.9 KB, free 365.8 MB)
18/07/13 19:14:46 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 130.192.16.68:20152 (size: 2.9 KB, free: 366.3 MB)
18/07/13 19:14:46 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
18/07/13 19:14:46 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[6] at mapToPair at SparkDriver.java:69) (first 15 tasks are for partitions Vector(0))
18/07/13 19:14:46 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
18/07/13 19:14:46 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4938 bytes)
18/07/13 19:14:47 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
18/07/13 19:14:47 INFO Executor: Fetching spark://130.192.16.68:19272/jars/Exam2018_07_16_Exercise2_v2-1.0.0.jar with timestamp 1531502085906
18/07/13 19:14:47 INFO TransportClientFactory: Successfully created connection to /130.192.16.68:19272 after 23 ms (0 ms spent in bootstraps)
18/07/13 19:14:47 INFO Utils: Fetching spark://130.192.16.68:19272/jars/Exam2018_07_16_Exercise2_v2-1.0.0.jar to /tmp/spark-864e0781-b15d-4edc-b72e-47bf32917cd9/userFiles-b6affdd5-aa26-45fc-8fd5-bfd53d0735b5/fetchFileTemp7674630953536084750.tmp
18/07/13 19:14:47 INFO Executor: Adding file:/tmp/spark-864e0781-b15d-4edc-b72e-47bf32917cd9/userFiles-b6affdd5-aa26-45fc-8fd5-bfd53d0735b5/Exam2018_07_16_Exercise2_v2-1.0.0.jar to class loader
18/07/13 19:14:47 INFO HadoopRDD: Input split: file:/home/paolo/Dropbox/owncloud/Corsi/BigData1718/Exams_AA1718/Exam20180716/BozzaSoluzionev2/Exercise2/exam_ex2_data/Robots.txt:0+108
18/07/13 19:14:47 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1025 bytes result sent to driver
18/07/13 19:14:47 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 4938 bytes)
18/07/13 19:14:47 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
18/07/13 19:14:47 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 241 ms on localhost (executor driver) (1/1)
18/07/13 19:14:47 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/07/13 19:14:47 INFO HadoopRDD: Input split: file:/home/paolo/Dropbox/owncloud/Corsi/BigData1718/Exams_AA1718/Exam20180716/BozzaSoluzionev2/Exercise2/exam_ex2_data/Faults.txt:0+1403
18/07/13 19:14:47 INFO DAGScheduler: ShuffleMapStage 0 (mapToPair at SparkDriver.java:40) finished in 0.265 s
18/07/13 19:14:47 INFO DAGScheduler: looking for newly runnable stages
18/07/13 19:14:47 INFO DAGScheduler: running: Set(ShuffleMapStage 1)
18/07/13 19:14:47 INFO DAGScheduler: waiting: Set(ShuffleMapStage 2, ResultStage 3)
18/07/13 19:14:47 INFO DAGScheduler: failed: Set()
18/07/13 19:14:47 INFO MemoryStore: Block rdd_5_0 stored as values in memory (estimated size 4.5 KB, free 365.8 MB)
18/07/13 19:14:47 INFO BlockManagerInfo: Added rdd_5_0 in memory on 130.192.16.68:20152 (size: 4.5 KB, free: 366.3 MB)
18/07/13 19:14:47 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1679 bytes result sent to driver
18/07/13 19:14:47 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 44 ms on localhost (executor driver) (1/1)
18/07/13 19:14:47 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
18/07/13 19:14:47 INFO DAGScheduler: ShuffleMapStage 1 (mapToPair at SparkDriver.java:69) finished in 0.272 s
18/07/13 19:14:47 INFO DAGScheduler: looking for newly runnable stages
18/07/13 19:14:47 INFO DAGScheduler: running: Set()
18/07/13 19:14:47 INFO DAGScheduler: waiting: Set(ShuffleMapStage 2, ResultStage 3)
18/07/13 19:14:47 INFO DAGScheduler: failed: Set()
18/07/13 19:14:47 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[10] at mapToPair at SparkDriver.java:88), which has no missing parents
18/07/13 19:14:47 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 4.7 KB, free 365.8 MB)
18/07/13 19:14:47 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.6 KB, free 365.8 MB)
18/07/13 19:14:47 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 130.192.16.68:20152 (size: 2.6 KB, free: 366.2 MB)
18/07/13 19:14:47 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
18/07/13 19:14:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[10] at mapToPair at SparkDriver.java:88) (first 15 tasks are for partitions Vector(0))
18/07/13 19:14:47 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
18/07/13 19:14:47 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 4673 bytes)
18/07/13 19:14:47 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
18/07/13 19:14:47 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 130.192.16.68:20152 in memory (size: 2.7 KB, free: 366.3 MB)
18/07/13 19:14:47 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/07/13 19:14:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
18/07/13 19:14:47 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/07/13 19:14:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/07/13 19:14:47 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1283 bytes result sent to driver
18/07/13 19:14:47 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 62 ms on localhost (executor driver) (1/1)
18/07/13 19:14:47 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
18/07/13 19:14:47 INFO DAGScheduler: ShuffleMapStage 2 (mapToPair at SparkDriver.java:88) finished in 0.062 s
18/07/13 19:14:47 INFO DAGScheduler: looking for newly runnable stages
18/07/13 19:14:47 INFO DAGScheduler: running: Set()
18/07/13 19:14:47 INFO DAGScheduler: waiting: Set(ResultStage 3)
18/07/13 19:14:47 INFO DAGScheduler: failed: Set()
18/07/13 19:14:47 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[13] at saveAsTextFile at SparkDriver.java:101), which has no missing parents
18/07/13 19:14:47 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 66.4 KB, free 365.8 MB)
18/07/13 19:14:47 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 23.9 KB, free 365.7 MB)
18/07/13 19:14:47 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 130.192.16.68:20152 (size: 23.9 KB, free: 366.2 MB)
18/07/13 19:14:47 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
18/07/13 19:14:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[13] at saveAsTextFile at SparkDriver.java:101) (first 15 tasks are for partitions Vector(0))
18/07/13 19:14:47 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
18/07/13 19:14:47 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, ANY, 4621 bytes)
18/07/13 19:14:47 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
18/07/13 19:14:47 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/07/13 19:14:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/07/13 19:14:47 INFO FileOutputCommitter: Saved output of task 'attempt_20180713191446_0003_m_000000_3' to file:/home/paolo/Dropbox/owncloud/Corsi/BigData1718/Exams_AA1718/Exam20180716/BozzaSoluzionev2/Exercise2/exam_ex2A_out/_temporary/0/task_20180713191446_0003_m_000000
18/07/13 19:14:47 INFO SparkHadoopMapRedUtil: attempt_20180713191446_0003_m_000000_3: Committed
18/07/13 19:14:47 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1138 bytes result sent to driver
18/07/13 19:14:47 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 48 ms on localhost (executor driver) (1/1)
18/07/13 19:14:47 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
18/07/13 19:14:47 INFO DAGScheduler: ResultStage 3 (saveAsTextFile at SparkDriver.java:101) finished in 0.050 s
18/07/13 19:14:47 INFO DAGScheduler: Job 0 finished: saveAsTextFile at SparkDriver.java:101, took 0.558045 s
18/07/13 19:14:47 INFO SparkContext: Starting job: saveAsTextFile at SparkDriver.java:185
18/07/13 19:14:47 INFO DAGScheduler: Registering RDD 14 (mapToPair at SparkDriver.java:110)
18/07/13 19:14:47 INFO DAGScheduler: Registering RDD 16 (mapToPair at SparkDriver.java:141)
18/07/13 19:14:47 INFO DAGScheduler: Got job 1 (saveAsTextFile at SparkDriver.java:185) with 1 output partitions
18/07/13 19:14:47 INFO DAGScheduler: Final stage: ResultStage 6 (saveAsTextFile at SparkDriver.java:185)
18/07/13 19:14:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
18/07/13 19:14:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
18/07/13 19:14:47 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[14] at mapToPair at SparkDriver.java:110), which has no missing parents
18/07/13 19:14:47 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 5.7 KB, free 365.7 MB)
18/07/13 19:14:47 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.1 KB, free 365.7 MB)
18/07/13 19:14:47 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 130.192.16.68:20152 (size: 3.1 KB, free: 366.2 MB)
18/07/13 19:14:47 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
18/07/13 19:14:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[14] at mapToPair at SparkDriver.java:110) (first 15 tasks are for partitions Vector(0))
18/07/13 19:14:47 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
18/07/13 19:14:47 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 4938 bytes)
18/07/13 19:14:47 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
18/07/13 19:14:47 INFO BlockManager: Found block rdd_5_0 locally
18/07/13 19:14:47 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1111 bytes result sent to driver
18/07/13 19:14:47 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 16 ms on localhost (executor driver) (1/1)
18/07/13 19:14:47 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
18/07/13 19:14:47 INFO DAGScheduler: ShuffleMapStage 4 (mapToPair at SparkDriver.java:110) finished in 0.017 s
18/07/13 19:14:47 INFO DAGScheduler: looking for newly runnable stages
18/07/13 19:14:47 INFO DAGScheduler: running: Set()
18/07/13 19:14:47 INFO DAGScheduler: waiting: Set(ShuffleMapStage 5, ResultStage 6)
18/07/13 19:14:47 INFO DAGScheduler: failed: Set()
18/07/13 19:14:47 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[16] at mapToPair at SparkDriver.java:141), which has no missing parents
18/07/13 19:14:47 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 4.4 KB, free 365.7 MB)
18/07/13 19:14:47 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.4 KB, free 365.7 MB)
18/07/13 19:14:47 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 130.192.16.68:20152 (size: 2.4 KB, free: 366.2 MB)
18/07/13 19:14:47 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
18/07/13 19:14:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[16] at mapToPair at SparkDriver.java:141) (first 15 tasks are for partitions Vector(0))
18/07/13 19:14:47 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
18/07/13 19:14:47 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, ANY, 4610 bytes)
18/07/13 19:14:47 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
18/07/13 19:14:47 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/07/13 19:14:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/07/13 19:14:47 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1283 bytes result sent to driver
18/07/13 19:14:47 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 11 ms on localhost (executor driver) (1/1)
18/07/13 19:14:47 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
18/07/13 19:14:47 INFO DAGScheduler: ShuffleMapStage 5 (mapToPair at SparkDriver.java:141) finished in 0.012 s
18/07/13 19:14:47 INFO DAGScheduler: looking for newly runnable stages
18/07/13 19:14:47 INFO DAGScheduler: running: Set()
18/07/13 19:14:47 INFO DAGScheduler: waiting: Set(ResultStage 6)
18/07/13 19:14:47 INFO DAGScheduler: failed: Set()
18/07/13 19:14:47 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[20] at saveAsTextFile at SparkDriver.java:185), which has no missing parents
18/07/13 19:14:47 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 66.7 KB, free 365.7 MB)
18/07/13 19:14:47 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 24.0 KB, free 365.6 MB)
18/07/13 19:14:47 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 130.192.16.68:20152 (size: 24.0 KB, free: 366.2 MB)
18/07/13 19:14:47 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
18/07/13 19:14:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[20] at saveAsTextFile at SparkDriver.java:185) (first 15 tasks are for partitions Vector(0))
18/07/13 19:14:47 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
18/07/13 19:14:47 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, ANY, 4621 bytes)
18/07/13 19:14:47 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
18/07/13 19:14:47 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/07/13 19:14:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/07/13 19:14:47 INFO FileOutputCommitter: Saved output of task 'attempt_20180713191447_0006_m_000000_6' to file:/home/paolo/Dropbox/owncloud/Corsi/BigData1718/Exams_AA1718/Exam20180716/BozzaSoluzionev2/Exercise2/exam_ex2B_out/_temporary/0/task_20180713191447_0006_m_000000
18/07/13 19:14:47 INFO SparkHadoopMapRedUtil: attempt_20180713191447_0006_m_000000_6: Committed
18/07/13 19:14:47 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1181 bytes result sent to driver
18/07/13 19:14:47 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 32 ms on localhost (executor driver) (1/1)
18/07/13 19:14:47 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
18/07/13 19:14:47 INFO DAGScheduler: ResultStage 6 (saveAsTextFile at SparkDriver.java:185) finished in 0.032 s
18/07/13 19:14:47 INFO DAGScheduler: Job 1 finished: saveAsTextFile at SparkDriver.java:185, took 0.096072 s
18/07/13 19:14:47 INFO SparkUI: Stopped Spark web UI at http://130.192.16.68:4040
18/07/13 19:14:47 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/07/13 19:14:47 INFO MemoryStore: MemoryStore cleared
18/07/13 19:14:47 INFO BlockManager: BlockManager stopped
18/07/13 19:14:47 INFO BlockManagerMaster: BlockManagerMaster stopped
18/07/13 19:14:47 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/07/13 19:14:47 INFO SparkContext: Successfully stopped SparkContext
18/07/13 19:14:47 INFO ShutdownHookManager: Shutdown hook called
18/07/13 19:14:47 INFO ShutdownHookManager: Deleting directory /tmp/spark-864e0781-b15d-4edc-b72e-47bf32917cd9
